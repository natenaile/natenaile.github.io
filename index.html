<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Natenaile Asmamaw Shiferaw</title>

    <meta name="author" content="Jon Barron">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Natenaile Asmamaw Shiferaw
                </p>
                <p>
		I'm currently an Erasmus Mundus master's student in <a href="https://www.master-photonics4security.eu/"> Intelligent Photonics for Security, Reliability, Sustainability and Safety (iPSRS)
        </a>, a joint triple-degree program offered by <a href="https://www.univ-st-etienne.fr/fr/index.html">Université Jean Monnet</a> (France), the <a href="https://www.uef.fi/en">University of Eastern Finland</a> (Finland),
        and <a href="https://www.u-pec.fr/">Université Paris-Est Créteil</a> (France). Previously, I completed my B.Tech in Computer Science and Engineering at <a href="https://cgu-odisha.ac.in/">C. V. Raman Global University</a>, India.


                </p>
                <p style="text-align:center">
                  <a href="mailto:natenshi@student.uef.fi">Email</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?hl=en&view_op=list_works&gmla=AL3_zihheqOoup2usHTpjAHPownvnqiKVf1PUDwBf-nI4RVPY4POE9hhAKqUjcfJ1OqrwiI65PqFIvMZRqbxZg&user=hnnHDZ8AAAAJ">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/natenaile-asmamaw-shiferaw-75884b260/"> LinkedIn</a> &nbsp;/&nbsp;
                  <a href="https://github.com/Natenaile">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:37%;max-width:37%">
                <a href="images/nati.png"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/nati.png" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  My background is in computer vision, with a strong foundation in machine learning. I am currently interested in computational imaging, 3D vision, and diffusion models.
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

<tr onmouseout="radmesh_stop()" onmouseover="radmesh_start()" bgcolor="#ffffd0">
  <td style="padding:16px;width:20%;vertical-align:middle">
    <div class="one">
      <div class="two" id='radmesh_image'>
        <img src='images/1b.png' width=100%>
      </div>
      <img src='images/1b.png' width=100%>
    </div>
    <script type="text/javascript">
      function radmesh_start() {
        document.getElementById('radmesh_image').style.opacity = "1";
      }

      function radmesh_stop() {
        document.getElementById('radmesh_image').style.opacity = "0";
      }
      radmesh_stop()
    </script>
  </td>
  <td style="padding:8px;width:80%;vertical-align:middle">
    <a href="https://ieeexplore.ieee.org/document/10935359?denied=">
      <span class="papertitle">Handwritten Amharic Character Recognition Through Transfer Learning: Integrating CNN Models and Machine Learning Classifiers</span>
    </a>
    <br>
	<strong>Natenaile Asmamaw Shiferaw</strong>,
    <a href="https://scholar.google.com/citations?user=y4sb4n4AAAAJ&hl=en">Zefree Lazarus Mayaluri</a>,
    <a href="https://scholar.google.com/citations?user=x5F_WSsAAAAJ&hl=en">Prabodh Kumar Sahoo</a>,
    <a href="https://scholar.google.com/citations?user=ooCsX-UAAAAJ&hl=en">Ganapati Panda</a>, <br>
	<a href="https://scholar.google.com/citations?user=iaDHE9wAAAAJ&hl=en">Prince Jain</a>, 
    <a href="https://scholar.google.com/citations?user=iJFfnJgAAAAJ&hl=en">Adyasha Rath</a>,
	<a href="https://scholar.google.com/citations?user=LFEfTUcAAAAJ&hl=en">MD. SHABIUL ISLAM</a>, 
    <a href="https://scholar.google.com/citations?user=X2k_pIYAAAAJ&hl=en">MOHAMMAD TARIQUL ISLAM</a>
    <br>
    <em>IEEE Access</em>, 2025
    <br>
    <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10935359">IEEE Access</a>
    <p></p>
    <p>
	Combining CNN-based feature extraction with classical machine learning classifiers enables accurate and robust recognition of handwritten Amharic characters, achieving strong performance for complex and underrepresented scripts.
    </p>
  </td>
</tr>


			  

<tr onmouseout="radmesh_stop()" onmouseover="radmesh_start()" bgcolor="#ffffd0">
  <td style="padding:16px;width:20%;vertical-align:middle">
    <div class="one">
      <div class="two" id='radmesh_image'>
        <img src='images/2a.png' width=100%>
      </div>
      <img src='images/2a.png' width=100%>
    </div>
    <script type="text/javascript">
      function radmesh_start() {
        document.getElementById('radmesh_image').style.opacity = "1";
      }

      function radmesh_stop() {
        document.getElementById('radmesh_image').style.opacity = "0";
      }
      radmesh_stop()
    </script>
  </td>

  <td style="padding:8px;width:80%;vertical-align:middle">
    <a href="https://or.niscpr.res.in/index.php/JSIR/article/view/15207">
      <span class="papertitle">An Efficient Baseline Restoration Circuit for Real-Time Impedance Cardiography: FPGA-Based Calibration with MultiSensor Integration</span>
    </a>
    <br>
    <a href="https://scholar.google.com/citations?user=mD0burkAAAAJ&hl=en">Priya Darshini Kumari</a>,
	<a href="https://scholar.google.com/citations?user=QgqSzgIAAAAJ&hl=en">Ksh Milan Singh</a>,
	<a href="https://scholar.google.com/citations?user=y4sb4n4AAAAJ&hl=en">Zefree Lazarus Mayaluri</a>,
	<strong>Natenaile Asmamaw Shiferaw</strong>,
    <a href="https://scholar.google.com/citations?user=ooCsX-UAAAAJ&hl=en">Ganapati Panda</a>, 
	<a href="https://scholar.google.com/citations?user=yRx7BO0AAAAJ&hl=en">Sujeevan Kumar Agir</a> 
    <br>
    <em>JSIR</em>, 2025
    <br>
    <a href="https://or.niscpr.res.in/index.php/JSIR/article/view/15207/4252">JSIR</a>
    <p></p>
    <p>
	Multisensor-driven adaptive baseline correction significantly reduces motion and respiratory artifacts in impedance cardiography for reliable real-time monitoring.
    </p>
  </td>
</tr>

<tr onmouseout="radmesh_stop()" onmouseover="radmesh_start()" bgcolor="#ffffd0">
  <td style="padding:16px;width:20%;vertical-align:middle">
    <div class="one">
      <div class="two" id='radmesh_image'>
        <img src='images/3a.jpg' width=100%>
      </div>
      <img src='images/3a.png' width=100%>
    </div>
    <script type="text/javascript">
      function radmesh_start() {
        document.getElementById('radmesh_image').style.opacity = "1";
      }

      function radmesh_stop() {
        document.getElementById('radmesh_image').style.opacity = "0";
      }
      radmesh_stop()
    </script>
  </td>
  <td style="padding:8px;width:80%;vertical-align:middle">
    <a href="https://arxiv.org/abs/2508.18960">
      <span class="papertitle">Enhancing compact convolutional transformers with super attention</span>
    </a>
    <br>
    <a href="https://scholar.google.com/citations?user=azw29DIAAAAJ&hl=en">Simpenzwe Honore Leandre*</a>,
	<strong>Natenaile Asmamaw Shiferaw*</strong>,
	<a href="https://scholar.google.com/citations?user=JHJT7r4AAAAJ&hl=en"> Dillip Rout</a> 
    <br>
    <em>arXiv</em>, 2025
    <br>
    <a href="https://arxiv.org/pdf/2508.18960">arXiv</a>
    <p></p>
    <p>
    A token-mixing vision architecture achieves strong accuracy and efficient inference on fixed-length image tasks, outperforming attention-based transformers with improved training stability.
    </p>
  </td>
</tr>

<tr onmouseout="radmesh_stop()" onmouseover="radmesh_start()" bgcolor="#ffffd0">
  <td style="padding:16px;width:20%;vertical-align:middle">
    <div class="one">
      <div class="two" id='radmesh_image'>
        <img src='images/4a.jpg' width=100%>
      </div>
      <img src='images/4a.png' width=100%>
    </div>
    <script type="text/javascript">
      function radmesh_start() {
        document.getElementById('radmesh_image').style.opacity = "1";
      }

      function radmesh_stop() {
        document.getElementById('radmesh_image').style.opacity = "0";
      }
      radmesh_stop()
    </script>
  </td>
  <td style="padding:8px;width:80%;vertical-align:middle">
    <a href="https://arxiv.org/abs/2411.14254">
      <span class="papertitle">BERT-Based Approach for Automating Course Articulation Matrix Construction with Explainable AI</span>
    </a>
    <br>
	<strong>Natenaile Asmamaw Shiferaw*</strong>,
    <a href="https://scholar.google.com/citations?user=azw29DIAAAAJ&hl=en">Simpenzwe Honore Leandre*</a>,
	<a href="https://www.linkedin.com/in/aman-sinha-ao2709003/?originalSubdomain=in">Aman Sinha</a>,
	<a href="https://scholar.google.com/citations?user=JHJT7r4AAAAJ&hl=en"> Dillip Rout</a> 
    <br>
    <em>arXiv</em>, 2024
    <br>
    <a href="https://arxiv.org/pdf/2411.14254">arXiv</a>
    <p></p>
    <p>
    An explainable BERT-based framework accurately automates Course Articulation Matrix construction by learning semantic alignment between course and program outcomes.    </p>
  </td>
</tr>



			  
<tr onmouseout="radmesh_stop()" onmouseover="radmesh_start()" bgcolor="#ffffd0">
  <td style="padding:16px;width:20%;vertical-align:middle">
    <div class="one">
      <div class="two" id='radmesh_image'>
        <img src='images/5a.jpg' width=100%>
      </div>
      <img src='images/5a.png' width=100%>
    </div>
    <script type="text/javascript">
      function radmesh_start() {
        document.getElementById('radmesh_image').style.opacity = "1";
      }

      function radmesh_stop() {
        document.getElementById('radmesh_image').style.opacity = "0";
      }
      radmesh_stop()
    </script>
  </td>
  <td style="padding:8px;width:80%;vertical-align:middle">
    <a href="https://drive.google.com/file/d/1AtyDksoXHROzIE5aXudeOnCOsVEvh38G/view">
      <span class="papertitle">Hybrid Hand Detection and Segmentation for Ego-Centric Interaction Using YOLO (v8-v11) and RT-DETR for Detection, Followed by SAM and SAM 2 for Segmentation</span>
    </a>
    <br>
	<strong>Natenaile Asmamaw Shiferaw*</strong>,
    <a href="https://scholar.google.com/citations?user=y4sb4n4AAAAJ&hl=en">Zefree Lazarus Mayaluri</a>,
	<a href="https://scholar.google.com/citations?user=x5F_WSsAAAAJ&hl=en">Prabodh Kumar Sahoo</a>,
    <a href="https://scholar.google.com/citations?user=ooCsX-UAAAAJ&hl=en">Ganapati Panda</a> 
    <br>
    <em> Elsevier's Image and Vision Computing</em>, Under review
    <br>
    <a href="https://drive.google.com/file/d/1AtyDksoXHROzIE5aXudeOnCOsVEvh38G/view">Elsevier</a>
    <p></p>
    <p>
    Combining lightweight YOLO-based detection with prompt-based SAM segmentation enables accurate ego-centric hand detection and segmentation for human–robot interaction.
	</p>
  </td>
</tr>
			  
<tr onmouseout="radmesh_stop()" onmouseover="radmesh_start()" bgcolor="#ffffd0">
  <td style="padding:16px;width:20%;vertical-align:middle">
    <div class="one">
      <div class="two" id='radmesh_image'>
        <img src='images/6a.jpg' width=100%>
      </div>
      <img src='images/6a.png' width=100%>
    </div>
    <script type="text/javascript">
      function radmesh_start() {
        document.getElementById('radmesh_image').style.opacity = "1";
      }

      function radmesh_stop() {
        document.getElementById('radmesh_image').style.opacity = "0";
      }
      radmesh_stop()
    </script>
  </td>
  <td style="padding:8px;width:80%;vertical-align:middle">
    <a href="https://drive.google.com/file/d/1CX547GF8AnbUyN2e-Q8ecWFI9KYQGv6_/view">
      <span class="papertitle">Lightweight Hybrid CNN–Transformer Ensembles with Explainable AI for Lung Disease Detection from Chest X-rays</span>
    </a>
    <br>
	<strong>Natenaile Asmamaw Shiferaw*</strong>,
    <a href="https://scholar.google.com/citations?user=y4sb4n4AAAAJ&hl=en">Zefree Lazarus Mayaluri*</a>
    <br>
    <em>IEEE JBHI</em>, Under review
    <br>
    <a href="https://drive.google.com/file/d/1CX547GF8AnbUyN2e-Q8ecWFI9KYQGv6_/view">IEEE JBHI</a>
    <p></p>
    <p>
    An efficient, explainable CNN–ViT ensemble approach delivers high-accuracy lung disease diagnosis from chest X-ray images.
	</p>
  </td>
</tr>

<tr onmouseout="radmesh_stop()" onmouseover="radmesh_start()" bgcolor="#ffffd0">
  <td style="padding:16px;width:20%;vertical-align:middle">
    <div class="one">
      <div class="two" id='radmesh_image'>
        <img src='images/7a.jpg' width=100%>
      </div>
      <img src='images/7a.png' width=100%>
    </div>
    <script type="text/javascript">
      function radmesh_start() {
        document.getElementById('radmesh_image').style.opacity = "1";
      }

      function radmesh_stop() {
        document.getElementById('radmesh_image').style.opacity = "0";
      }
      radmesh_stop()
    </script>
  </td>
  <td style="padding:8px;width:80%;vertical-align:middle">
    <a href="https://drive.google.com/file/d/1eIaiWwTz9428xqG7ufSMhCWxmXPNAWf3/view">
      <span class="papertitle">Comparative Analysis of YOLOv8 and YOLOv11 for Brain Tumor Instance Segmentation</span>
    </a>
    <br>
	<strong>Natenaile Asmamaw Shiferaw*</strong>,
    <a href="https://scholar.google.com/citations?user=azw29DIAAAAJ&hl=en">Simpenzwe Honore Leandre*</a>,
	<a href="https://scholar.google.com/citations?user=JHJT7r4AAAAJ&hl=en"> Dillip Rout</a>, 
	<a href="https://www.linkedin.com/in/aman-sinha-ao2709003/?originalSubdomain=in">Aman Sinha</a>
    <br>
    <em>MAiTRI</em>, 2025 (Accepted)
    <br>
    <a href="https://drive.google.com/file/d/1eIaiWwTz9428xqG7ufSMhCWxmXPNAWf3/view">IEEE JBHI</a>
    <p></p>
    <p>
    A YOLO-based instance segmentation framework enables efficient and accurate localization and delineation of brain tumors in medical images.
	</p>
  </td>
</tr>			  
<tr onmouseout="nexf_stop()" onmouseover="nexf_start()">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='nexf_image'>
					  <img src='images/nexf_after.jpg' width=100%>
					</div>
          <img src='images/nexf_before.jpg' width=100%>
        </div>
        <script type="text/javascript">
          function nexf_start() {
            document.getElementById('nexf_image').style.opacity = "1";
          }

          function nexf_stop() {
            document.getElementById('nexf_image').style.opacity = "0";
          }
          nexf_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://m-niemeyer.github.io/nexf/">
          <span class="papertitle">NExF: Learning Neural Exposure Fields for View Synthesis</span>
        </a>
        <br>
        <a href="https://m-niemeyer.github.io/">Michael Niemeyer</a>,
        <a href="https://campar.in.tum.de/Main/FabianManhardt">Fabian Manhardt</a>,
        <a href="http://www.lix.polytechnique.fr/Labo/Marie-Julie.RAKOTOSAONA/">Marie-Julie Rakotosaona</a>,
        <a href="https://moechsle.github.io">Michael Oechsle</a>,
        <a href="https://ait.ethz.ch/people/ctsalico">Christina Tsalicoglou</a>,
        <a href="https://scholar.google.com/citations?user=ml3laqEAAAAJ&hl=ja">Keisuke Tateno</a>,
        <strong>Jonathan T. Barron</strong>,
        <a href="https://federicotombari.github.io/">Federico Tombari</a>
        <br>
        <em>NeurIPS</em>, 2025
        <br>
        <a href="https://m-niemeyer.github.io/nexf/">project page</a>
        /
        <a href="https://arxiv.org/abs/2510.08279">arXiv</a>
        <p></p>
        <p>
		Learning a neural field that optimizes exposure for each 3D point enables high-quality 3D-consistent view synthesis despite extreme exposure variation during capture.
        </p>
      </td>
    </tr>
          </tbody></table>

          
					<table style="width:100%; margin:0 auto; border:0; border-spacing:0; padding:16px;"><tbody>
            <tr>
              <td>
                <h2>Miscellanea</h2>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            
           
            <tr>
              <td align="center" style="padding:16px;width:20%;vertical-align:middle">
						     <div class="colored-box" style="background-color: #fcb97d;">
								 <h2>Micropapers</h2>
								 </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://arxiv.org/abs/2112.11687">Squareplus: A Softplus-Like Algebraic Rectifier</a>
                <br>
                <a href="https://arxiv.org/abs/2010.09714">A Convenient Generalization of Schlick's Bias and Gain Functions</a>
                <br>
                <a href="https://arxiv.org/abs/1704.07483">Continuously Differentiable Exponential Linear Units</a>
                <br>
                <a href="https://jonbarron.info/data/cvpr2023_llm_workshop_annotated.pdf">Scholars & Big Models: How Can Academics Adapt?</a>
              </td>
            </tr>


            <tr>
              <td align="center" style="padding:16px;width:20%;vertical-align:middle">
						     <div class="colored-box" style="background-color: #aaba9e;">
								 <h2>Recorded Talks</h2>
								 </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:center">
                <a href="https://www.youtube.com/watch?v=hFlF33JZbA0">Radiance Fields and the Future of Generative Media, 2025</a><br>				  
                <a href="https://www.youtube.com/watch?v=h9vq_65eDas">View Dependent Podcast, 2024</a><br>
                <a href="https://www.youtube.com/watch?v=4tDhYsFuEqo">Bay Area Robotics Symposium, 2023
</a><br>
                <a href="https://youtu.be/TvWkwDYtBP4?t=7604">EGSR Keynote, 2021</a><br>
				<a href="https://www.youtube.com/watch?v=nRyOzHpcr4Q">TUM AI Lecture Series, 2020</a><br>
				<a href="https://www.youtube.com/watch?v=HfJpQCBTqZs">Vision & Graphics Seminar at MIT, 2020</a>
              </td>
            </tr>

            <tr>
              <td align="center" style="padding:16px;width:20%;vertical-align:middle">
						     <div class="colored-box" style="background-color: #c6b89e;">
								 <h2>Academic Service</h2>
								 </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:center">
                <a href="https://iccv.thecvf.com/">Lead Area Chair, ICCV 2025</a>
                <br>
                <a href="https://cvpr.thecvf.com/Conferences/2025/Organizers">Lead Area Chair, CVPR 2025</a>
                <br>
                <a href="https://cvpr.thecvf.com/Conferences/2024/Organizers">Area Chair, CVPR 2024</a>
                <br>
                <a href="https://cvpr2023.thecvf.com/Conferences/2023/Organizers">Demo Chair, CVPR 2023</a>
                <br>
                <a href="https://cvpr2022.thecvf.com/area-chairs">Area Chair, CVPR 2022</a>
                <br>
                <a href="http://cvpr2021.thecvf.com/area-chairs">Area Chair & Award Committee Member, CVPR 2021</a>
                <br>
                <a href="http://cvpr2019.thecvf.com/area_chairs">Area Chair, CVPR 2019</a>
                <br>
                <a href="http://cvpr2018.thecvf.com/organizers/area_chairs">Area Chair, CVPR 2018</a>
              </td>
            </tr>
						
						
           
            <tr>
              <td align="center" style="padding:16px;width:20%;vertical-align:middle">
						     <div class="colored-box" style="background-color: #edd892;">
								 <h2>Teaching</h2>
								 </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:center">
                <a href="http://inst.eecs.berkeley.edu/~cs188/sp11/announcements.html">Graduate Student Instructor, CS188 Spring 2011</a>
                <br>
                <a href="http://inst.eecs.berkeley.edu/~cs188/fa10/announcements.html">Graduate Student Instructor, CS188 Fall 2010</a>
                <br>
                <a href="http://aima.cs.berkeley.edu/">Figures, "Artificial Intelligence: A Modern Approach", 3rd Edition</a>
              </td>
            </tr>
            
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  Feel free to steal this website's <a href="https://github.com/jonbarron/jonbarron_website">source code</a>. <strong>Do not</strong> scrape the HTML from this page itself, as it includes analytics tags that you do not want on your own website &mdash; use the github code instead. Also, consider using <a href="https://leonidk.com/">Leonid Keselman</a>'s <a href="https://github.com/leonidk/new_website">Jekyll fork</a> of this page.
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
